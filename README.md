# Awesome-Document-Layout-Analysis
A curated list of resources dedicated to document layout analysis
## 1. Papers

* *CODE means official code and CODE means not official code

*Conf.* | *Date* | *Title* | *Highlight* | *code* 
:---: | :---: |:--- | :---: | :---: 
ICDAR2021 | 2021/5/13 |[VSR: A Unified Framework for Document Layout Analysis combining Vision, Semantics and Relations](https://arxiv.org/pdf/2105.06220.pdf) | V,S,R | [*CODE](https://github.com/hikopensource/DAVAR-Lab-OCR/tree/main/demo/text_layout/VSR)<br/>![](https://img.shields.io/github/stars/hikopensource/DAVAR-Lab-OCR.svg?style=social) 
KDD 2020 | 2020/6/16 |[LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/pdf/1912.13318.pdf) | multimodal/pretrain | [*CODE](https://github.com/microsoft/unilm/tree/master/layoutlm)<br/>![](https://img.shields.io/github/stars/microsoft/unilm.svg?style=social) 
ACL2021 | 2022/1/10 |[LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding](https://arxiv.org/pdf/2012.14740.pdf) | multimodal/pretrain | [*CODE](https://github.com/microsoft/unilm/tree/master/layoutlmv2)<br/>![](https://img.shields.io/github/stars/microsoft/unilm.svg?style=social) 

## 2. Datasets
### 2.1 Introduction

|Dataset|Description|dataset link|
|----|----|----|
|PubLayNet|PubLayNet is a large dataset of document images, of which the layout is annotated with both bounding boxes and polygonal segmentations.The annotations are automatically generated by matching the PDF format and the XML format.The size of the dataset is comparable to established computer vision datasets, containing over 360 thousand document images, where typical document layout elements are annotated.|[PubLayNet](https://github.com/ibm-aur-nlp/PubLayNet)|
|DocBank|DocBank is a new large-scale dataset that is constructed using a weak supervision approach. It enables models to integrate both the textual and layout information for downstream tasks. The current DocBank dataset totally includes 500K document pages, where 400K for training, 50K for validation and 50K for testing.|[DocBank](https://github.com/doc-analysis/DocBank)|

### 2.2 Comparison of datasets for table structure recognition
TO DO

## 3. Other technical solutions
### 3.1 Relevant research institutions and scholars 
- [document AI](https://www.microsoft.com/en-us/research/project/document-ai/)
  
  - [Minghao Li](https://github.com/liminghao1630)
  - [Yiheng Xu](https://github.com/ranpox)
  
  
### 3.2 Related competitions
- [ICDAR 2021 Competition on Scientific Literature Parsing](https://github.com/IBM/ICDAR2021-SLP) ([Task A on Document Layout Recognition](https://aieval.draco.res.ibm.com/challenge/41/overview))
  
  - First Place Method: [Davar-Lab-OCR: VSR](https://github.com/hikopensource/DAVAR-Lab-OCR/tree/main/demo/text_layout/VSR)
  
  

### 3.3 Related lecture

* 2021

  * MSR: [Document AI: Benchmarks, Models and Applications (Presentation@ICDAR 2021)](https://www.microsoft.com/en-us/research/publication/document-ai-benchmarks-models-and-applications-presentationicdar-2021/)

  

 

